% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\date{}

\begin{document}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

All the time, the Information and Communication Technology is providing
society with a vast variety of new distributed applications aimed at
micro and macro optimization of the industrial processes. Obviously, the
design foundation of this kind of application has to focus primarily on
communication technologies. Based on the role humans take while using
these applications they can be grouped as follows:

\begin{itemize}
\tightlist
\item
  \textbf{human-centric} - information origin or ultimate information
  destination is an operator,
\item
  \textbf{machine-centric} - information creation, consumption,
  networking, and processing are achieved entirely without human
  interaction.
\end{itemize}

A typical \textbf{human-centric} approach is a web-service supporting,
for example, a web user interface (UI) to monitor conditions, and manage
millions of devices and their data in a typical cloud-based IoT
approach. It is characteristic that, in this case, any uncertainty and
necessity to make a decision can be relaxed by human interaction.
Coordination of robots behavior in a work-cell (automation islands) is a
\textbf{machine-centric} example. In this case, it is essential that any
human interaction is impractical or even impossible. This
interconnection scenario requires the machine to machine communication
(M2M) demanding multi-vendor devices integration.

From the M2M communication concept, a broader concept of a smart factory
can be derived. In this concept, the mentioned robots are only executive
assets of an integrated supervisory control system responsible for macro
optimization of an industrial process composed into one whole.
Deployment of the smart factory concept requires a hybrid solution and
interconnection of the mentioned above heterogeneous environments. This
approach is called the fourth industrial revolution and coined as
Industry 4.0. It is worth stressing that machines - or more general
assets - interconnection is not enough, and additionally, assets
interoperability has to be expected for the deployment of this concept.
In this case, muli-vendor integration makes communication
standardization especially important, namely it is required that the
payload of the message is standardized to be factored on the gathering
site and consumed on the ultimate destination site.

Highly-distributed solutions used to control real-time process
aggregating islands of automation (e.g.~virtual power plants producing
renewable energy) additionally must leverage public communication
infrastructure, namely the Internet. Internet is a demanding environment
for highly distributed process control applications designed atop the
M2M communication paradigm because

\begin{itemize}
\tightlist
\item
  it is a globally shareable environment and can be also used by
  malicious users
\item
  it offers only non-deterministic communication making integration of
  islands of automation designed against the real-time requirements a
  difficult task
\end{itemize}

Today both obstacles can be overcome, and as examples, we have bank
account remote control and voice over IP in daily use. The first
application must be fine-tuned in the context of data security, and the
second is very sensitive on time relationships. Similar approaches could
be applied to adopt the well known in process control industry concepts:

\begin{itemize}
\tightlist
\item
  Human Machine Interface (HNI)
\item
  Supervisory Control and Data Acquisition (SCADA)
\item
  Distributed Control Systems (DCS)
\end{itemize}

A detailed examination of these solutions is far beyond the scope of
this article. It is only worth stressing that, by design, all of them
are designed on the foundation of interactive communication. Interactive
communication is based on a data polling foundation. In this case, the
application must follow the interactive behavioral model, because it
actively polls the data source for more information by pulling data from
a sequence that represents the process state in time. The application is
active in the data retrieval process - it controls the pace of the
retrieval by sending the requests at its convenience. Such a polling
pattern is similar to visiting the books shop and checking out a book.
After you are done with the book, you pay another visit to check out
another one. If the book is not available you must wait, but you may
read what you selected. The client/server archetype is well suited for
the mentioned above applications.

After dynamically attaching a new island of automation the control
application (responsible for the data pulling) must be reconfigured for
this interoperability scenario. In other words, in this case, the
interactive relationship cannot be directly applied because the control
application must be informed on how to pull data from a new source. As a
result, a plug and produce scenario cannot be seamlessly applied. A
similar drawback must be overcome if for security reasons suitable
protection methods have been applied to make network traffic propagation
asymmetric. It is accomplished using intermediary devices, for example,
firewalls, to enforce traffic selective availability based on
predetermined security rules against unauthorized access.

Going further, we shall assume that islands of automation are mobile,
e.g.~autonomous cars passing a supervisory controlled service area. In
this case, the behavior of the interconnected assets is particularly
important concerning the environment in which they must interact. This
way we have entered the Internet of Things domain of Internet-based
applications.

If we must bother with the network traffic propagation asymmetry or
mobility of the asset network attachment-points the reactive
relationship could relax the problems encountered while the interactive
approach is applied. In this case, the sessionless publisher-subscriber
communication archetype is a typical pattern to implement the abstract
reactive interoperability paradigm. The sessionless archetype is a
message distribution scenario where senders of messages, called
publishers, do not send them directly to specific receivers, called
subscribers, but instead, categorize the published messages into topics
without knowledge about which subscribers if any, there may be.
Similarly, subscribers express interest in one or more topics and only
receive messages that are of interest, without knowledge about which
publishers, if any, there are. In this scenario, the publishers and
subscribers are loosely coupled.i.e they are decoupled in time, space
and synchronization \cite{RefWorks:doc:5c44e246e4b0591b15ea9e59}.

If the \textbf{machine-centric} interoperability - making up islands of
automation - must be monitored and/or controlled by a supervisory system
cloud computing concept may be recognized as a beneficial solution to
replace or expand the mentioned above applications, i.e.~HMI, SCADA,
DCS, etc. Cloud computing is a method to provide a requested
functionality as a set of services. There are many examples that cloud
computing is useful to reduce costs and increase robustness. It is also
valuable in case the process data must be exposed to many stakeholders.
Following this idea and offering control systems as a service, there is
required a mechanism created on the service concept and supporting
abstraction and virtualization - two main pillars of the cloud computing
paradigm. In the cloud computing concept, virtualization is recognized
as the possibility to share the services by many users, and abstraction
hides implementation details.

Deployment of the hybrid solution providing interoperability of the
\textbf{machine-centric} cyber-physical systems and
\textbf{human-centric} cloud-based front-end can be implemented applying
the following scenarios:

\begin{itemize}
\tightlist
\item
  \textbf{direct interconnection} - cloud-based dedicated communication
  services allow to attache it to the cyber-physical system making up a
  consistent M2M communication network using an in-bound protocol stack
\item
  \textbf{gateway based interconnection} - typical build-in
  communication services allows to attache the cloud computing to the
  cyber-physical system using an out-of-bound protocol stack
\end{itemize}

By design, the direct approach requires that the cloud has to be
compliant with the interoperability standard the cyber-physical system
is built around - it becomes a consistent part of the cyber-physical
system. Data models, roles, and responsibility differences of both
solutions make this approach impractical and imposable to be applied in
typical cases. A more detailed description is covered by the section
\texttt{Azure\ to\ Sensors\ (A2S)\ connectivity\ deployment}.

This article addresses further research on the integration of the
cyber-physical systems in the context of new emerging disciplines,
i.e.~Industry 4.0 (I4.0) and the Internet of Things (IoT). The new
architecture is proposed for integration of the multi-vendor
\textbf{machine-centric} cyber-physical system designed atop of M2M
reactive communication and emerging cloud computing as a
\textbf{human-centric} front-end. To support the multi-vendor
environment OPC Unified Architecture interoperability standard has been
selected. The proposals are backed by proof of concept reference
implementations. Prototyping addresses Microsoft Azure Cloud as an
example. The prototyping outcome has been just published on GitHub as
the open-source (MIT licensed). The proposed solutions have been
harmonized with the more general concept called the Object-Oriented
Internet.

The main goal of this article is to provide proof that:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  reactive interoperability M2M communication based on the OPC UA
  standard can be implemented as a powerful standalone library without
  dependency on the Client/Server session-oriented archetype
\item
  Azure interoperability can be implemented as an external part
  employing out-of-band communication without dependency on the OPC UA
  implementation
\item
  the proposed generic architecture allows that the gateway
  functionality is composable at run-time - no programming required
\end{enumerate}

The remainder of this paper is structured as follows. Sect.
\texttt{Azure\ Main\ Technology\ \ Features} analyzes data presentation
user interface, available native communication services, and
data/metadata model offered by the Microsoft Azure. The discussion
covered by this section is the foundation for selecting services
utilized to expose process data and suitable protocol stack to support
interconnection. In Sect.
\texttt{Object-Oriented\ Internet\ Main\ Technology\ Features} the
discussion focuses on the generic architecture that is to be used as a
foundation for further decisions addressing the systematic design of the
interoperability of the cyber-physical systems and cloud-based
front-end. Sect.
\texttt{Azure\ to\ Sensors\ (A2S)\ connectivity\ deployment\ (field\ level\ connectivity)}
presents the proposed open and reusable software model. It promotes a
reactive interoperability pattern and a generic approach to establishing
interoperability-context. A reference implementation of this archetype
is described in Sect. \texttt{Gateway\ implementation}. The most
important findings and future work are summarized in Sect.
\texttt{Conclusions}.

\hypertarget{consider-to-add}{%
\subsection{Consider to add}\label{consider-to-add}}

\hypertarget{scope}{%
\subsubsection{Scope}\label{scope}}

What we must do to prove the goal have been achieved. Extent or range of
development, view, outlook, application, operation, effectiveness, etc.

\hypertarget{related-work}{%
\subsubsection{Related work}\label{related-work}}

Any information about available reusable deliverables related to this
work. \# Azure Main Technology Features

\hypertarget{services}{%
\subsection{Services}\label{services}}

Deployment of the hybrid solution providing interoperability of the
\textbf{machine-centric} cyber-physical systems designed atop of M2M
reactive communication and emerging cloud computing as a
\textbf{human-centric} front-end requires decisions addressing the
selection of the services supporting web user interface capable to
expose real-time process data. In this context, the service is any
autonomous (with own identity) software component or module that is
interfacing with selected cyber-physical systems for data collection,
analysis, and also remote control. Microsoft Azure is a cloud-based
product. It offers a vast variety of services. This virtual environment
handles an unlimited number of users and devices organized using a
solution concept. The solution aggregates users, devices, services, and
required additional resources scoping on a selected scenario. The
solution serves as a context that provides a scope to the identifiers
(the names of devices, users, process data entities, etc) inside it.
Solutions are used to organize deployment entities into logical groups
and prevent identity collisions.

The \texttt{IoT\ Central} service provides a process data visualization
user interface. To make this interface meaningful metadata called device
template is used to describe devices.

Following the assumption that interconnection between the cyber-physical
system and cloud services is designed based on the gateway concept, a
middleware must be considered as a coupler. It must be interconnected
with the cyber-physical system using an in-band protocol adhering to
communications requirements (i.e.~protocol profile, data encoding, time
relationships, etc.) governing communication of the parts making it up.
At the same time, it must support back-and-forth data transfer to the
cloud using out-of-band native for the cloud services. The transfer
process requires data conversion from source to destination encoding.
The \texttt{IoT\ Hub} is a service hosted in the cloud that supports
\texttt{IoT\ Central} providing a robust messaging solution - it acts as
a central message hub for bi-directional communication. This
communication is transparent, i.e.~it is not data types aware allowing
any devices to exchange any kind of data. This service is responsible to
manage the devices' identity and it offers the following protocol
stacks: AMQP, MQTT, HTTPS.

Before process data can be exposed using a web user interface the data
source must be associated with an appropriate solution and validated to
make sure that the security rules are not violated. It is hard to assume
that the security rules governing the cyber-physical system may also
apply to the cloud-based services. In the gateway scenario, they can be
mapped on each other or entirely independent. The
\texttt{IoT\ Hub\ Device\ Provisioning\ Service} (DPS) is a helper
service for \texttt{IoT\ Hub} that enables devices' connection process
management, upon device providing valid identity attestation it assigns
the device to an appropriate \texttt{IoT\ Hub} instance and returns to
the device connection parameters, which allow direct connection with
given \texttt{IoT\ Hub} service. The device proceeds to use the same
attestation in \texttt{IoT\ Hub} connection and based on it, is granted
authorization to selected resources and operations including but not
limited to data transfer updating the user interface.

It is worth stressing that interaction of the offered by the Azure
services can be configured flexibly, and as a result, the presented
above selection of services must be recognized as an example only. The
\texttt{IoT\ Central} can be also seamlessly integrated with other
services as needed. The following services could also be considered to
build cloud-based automation solution:

\begin{itemize}
\tightlist
\item
  \texttt{Industrial\ IoT} - discovering OPC UA enabled servers in a
  factory network and register them in Azure IoT Hub implemented using
  \texttt{IoT\ Edge}
\item
  \texttt{Digital\ Twins} - managing the graph of digital twins, which
  are to represent some real-world process or entity
\end{itemize}

\texttt{Industrial\ IoT} promotes OPC UA client/server archetype used to
achieve direct and interactive interoperability implemented using
\texttt{IoT\ Edge} services that allow extracting initial data
processing to local premises based on the edge concept.
\texttt{Digital\ Twins} is an emerging concept to use an observer to
replicate selected process state and behavior. The possibility to add
value as a result of using these services must be subject to further
research.

\hypertarget{data-interchange}{%
\subsection{Data Interchange}\label{data-interchange}}

System components interoperability means the necessity of the
information exchange between them. The main challenge of
interoperability implementation is that information is abstract -- it is
knowledge describing the process in concern state and behavior,
e.g.~temperature in a boiler, a car speed, an account balance, etc.
Obviously, abstraction cannot be processed by the cyber-physical
machines. It is also impossible to transfer abstraction from one place
to another over the network.

Fortunately, computer science offers a workaround to address that
impossibility - the information must be represented as a binary stream.
In consequence, we can usually use both ones as interchangeable terms
while talking about ICT systems. Unfortunately, these terms must be
precisely observed in the context of further discussion, because we must
be aware of the fact that the same information could have many different
but equivalent representations. In other words, the same information can
be represented by a vast variety of different binary patterns. For
example, numbers may be represented using 2's Complement and
Floating-Point binary representations.

It should be nothing new for us, as it is obvious that the same
information printed as a text in regional newspapers in English, German,
Polish, etc. does not resemble one another, but the text meaning should
always be the same. To understand a newspaper we must learn the
appropriate language. To understand the binary data we must have defined
a data type -- a description of how to create an appropriate bits
pattern (syntax) and rules needed to assign the information (semantics),
i.e.~make any correct bitstream meaningful. Concluding, to make two
systems interoperable, a semantic-context must be established. The type
plays the role of metadata, a set of data that describes other data.
Metadata term is frequently used if the semantic-context is defined
using a native language to select built-in types engaging a
general-purpose graphical user interface.

Using the data type definitions to describe information interchanged
between communicating parties allows:

\begin{itemize}
\tightlist
\item
  Development against a type definition of the user interface
\item
  Implementation of the functionality of the bitstreams conversion in
  advance
\end{itemize}

Having defined types in advance, a gateway may provide dedicated
conversions functionality, i.e.~replacing bitstream used by the
cyber-physical system by equivalent one for the cloud-based services.
The Azure offers a vast variety of built-in types ready to be used in
common cases, but not necessarily there are equivalent counterparts in
use by the cyber-physical system. Additionally, the data conversion must
address the following issues:

\begin{itemize}
\tightlist
\item
  usually to covert data from source to destination representation, the
  middleware software native types must be used
\item
  if the out of the box set of types is not capable of fulfilling more
  demanding needs, custom data types must be defined
\end{itemize}

Although the data conversion is a run-time gateway task the
implementation of the conversion algorithms must be recognized as an
engineering task, and therefore this topic is not considered for further
discussion.

In \texttt{IoT\ Central} a cyber-physical system is represented as a set
of devices. The characteristics and behaviors of each device kind are
described by the device template. This Device Template (DT) contains
also metadata describing the data (called telemetry) exchanged over the
wire with the cyber-physical system called Device Capability Model
(DCM). Additionally, the DT contains properties, customization, and
views definitions used by the service locally. As an option, DCM
expressed as a JSON-LD can be imported into a Device Template.
\texttt{IoT\ Central} allows also to create and edit a DCM using the
dedicated web UI. A JSON file containing DCM can be derived from an
information model used as a foundation to establish the semantic-context
applied to achieve interoperability of the devices interconnected as the
cyber-physical system. DCM development against any external information
model is a design-time task and should be supported by dedicated
development tools. In any case, the data interchanged between the cloud
and the gateway must be compliant with the DCM, hence the middleware
software must be aware of conversions that must be applied to achieve
this interoperability.

\hypertarget{connectivity}{%
\subsection{Connectivity}\label{connectivity}}

From the cloud side, it is proposed to employ the \texttt{IoT\ Hub}
service to handle the network traffic targeting the cyber-physical
system. This service offers profiles of the AMQP, MQTT, HTTPS protocol
stacks. In any case, process data (telemetry) is transparently
transferred back-and-forth to the upper layer \texttt{IoT\ Central}
service. Hence, the payload formatting is determined by the DCM
associated with the \texttt{IoT\ Central} solution. All the mentioned
protocols are standard ones. Consequently, it is possible to apply any
available implementation compliant with an appropriate specification to
achieve connectivity. In this case, all parameters required to establish
connectivity and security-context is up to the external software
responsibility. Alternatively, the API offered by the dedicated
libraries may be used. Using this API the configuration process can be
reduced significantly. Using these libraries, the selection of the
communication protocol has an indirect impact on the interoperability
features, including performance. The connectivity with
\texttt{IoT\ Hub}, for example, can be obtained using:

\begin{itemize}
\tightlist
\item
  \texttt{Microsoft.Azure.Devices} - Service SDK for Azure IoT Devices
\item
  \texttt{Microsoft.Azure.Devices.Client}- Device SDK for Azure IoT Hub
\item
  \texttt{Microsoft.Azure.Devices.Shared} - Common code for Azure IoT
  Device and Service SDKs
\item
  \texttt{Microsoft.Azure.Devices.Provisioning.Client} - Provisioning
  Device Client SDK for Azure IoT Devices
\item
  \texttt{Microsoft.Azure.Devices.Provisioning.Transport.Amqp} -
  Provisioning Device Client AMQP Transport for Azure IoT Devices
\item
  \texttt{Microsoft.Azure.Devices.Provisioning.Transport.Http} -
  Provisioning Device Client Http Transport for Azure IoT Devices
\item
  \texttt{Microsoft.Azure.Devices.Provisioning.Transport.Mqtt} -
  Provisioning Device Client MQTT Transport for Azure IoT Devices
\end{itemize}

\hypertarget{reactive-machine-to-machine-communication-state-of-the-art}{%
\section{Reactive Machine to Machine communication state of the
art}\label{reactive-machine-to-machine-communication-state-of-the-art}}

\hypertarget{opc-ua-pubsub-main-technology-features}{%
\subsection{OPC UA PubSub Main Technology
Features}\label{opc-ua-pubsub-main-technology-features}}

\hypertarget{ooi-main-technology-features}{%
\subsection{OOI Main Technology
Features}\label{ooi-main-technology-features}}

To address multi-vendor environment a standard solution is required.
=\textgreater{} PubSub. The specyfication is abstrack, so concrete
oimplementation has been selected OOI.

\begin{itemize}
\tightlist
\item
  Protocol stack
\item
  DataTypes binary and JSON encoding
\item
  Data Transfer Object embedded in the NetworkMessage
\end{itemize}

\hypertarget{problem}{%
\subsection{Problem}\label{problem}}

As stated in Sec. 1 the interoperability of the \textbf{machine-centric}
cyber-physical systems and \textbf{human-centric} cloud-based front-end
can be implemented applying one of the following scenarios:

\begin{itemize}
\tightlist
\item
  \textbf{direct interconnection} - cloud-based dedicated communication
  services allow to attach it to the cyber-physical system making up a
  consistent M2M communication network using its protocol stack
\item
  \textbf{gateway based interconnection} - native build-in communication
  services allows attaching the cloud to the cyber-physical system using
  an out-of-bound protocol stack
\end{itemize}

By design, the direct approach requires that the cloud has to be
compliant with the interoperability standard the cyber-physical system
uses. As a result, it becomes a consistent part of the cyber-physical
system.

Data models, roles, and responsibility differences of both solutions
make this approach imposable or impractical in typical cases.

This article addresses further research on the integration of the
cyber-physical systems in the context of new emerging disciplines,
i.e.~Industry 4.0 (I4.0) and the Internet of Things (IoT). The new
architecture is proposed for integration of the multi-vendor
\textbf{machine-centric} cyber-physical system designed atop of M2M
reactive communication and emerging cloud computing as a
\textbf{human-centric} front-end. To support the multi-vendor
environment OPC Unified Architecture interoperability standard has been
selected. The proposals are backed by proof of concept reference
implementations. Prototyping addresses Microsoft Azure Cloud as an
example. The prototyping outcome has been just published on GitHub as
the open-source (MIT licensed). The proposed solutions have been
harmonized with the more general concept called the Object-Oriented
Internet.

how to interconnect two completely different environment:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  machine-centric reactive interoperability addressing real-time mobile
  applications
\item
  human-centric interactive web based user graphical interface
\end{enumerate}

\hypertarget{architecture-scenarios}{%
\subsection{Architecture scenarios}\label{architecture-scenarios}}

\begin{itemize}
\tightlist
\item
  tightly coupled - treat Azure as tightly coupled communication part of
  the m2m
\item
  loosely coupled - use gateway as the intensional man in the middle
\end{itemize}

\hypertarget{requirements}{%
\subsection{Requirements}\label{requirements}}

\begin{itemize}
\tightlist
\item
  standard base
\item
  reactive interoperability (sessionless)
\item
  gateway architecture

  \begin{itemize}
  \tightlist
  \item
    gateway is part of the M2M communication network (in-baud )
  \item
    out-of-band communication - asynchronous data exchange
  \item
    semantic-context integration (types mapping)
  \item
    security context independency
  \item
    separation of concerns - composable implementation
  \end{itemize}
\end{itemize}

\hypertarget{library-selection-against-the-problem}{%
\subsection{Library selection against the
problem}\label{library-selection-against-the-problem}}

It is real a The defined in sec.~problem is engineering challenge is how
to interconnect two completely different environment:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  machine centric reactive interoperability addressing real-time mobile
  applications
\item
  human centric interactive web based user graphical interface
\end{enumerate}

Why reactive interoperability

\begin{itemize}
\tightlist
\item
  data mobility
\item
  network trafik asymmetry
\item
  serverless implementation (self contained implementation)
\end{itemize}

\hypertarget{sessionless}{%
\subsection{Sessionless}\label{sessionless}}

\begin{itemize}
\tightlist
\item
  Without a session; taking the form of a series of isolated requests.
\item
  System having virtual session manager used sessionless-oriented
  protocol to communicate with user device via wireless channel and
  session-oriented protocol to communicate with host server
\end{itemize}

\hypertarget{library-description-targeting-reactive-interoperability}{%
\subsection{Library description targeting reactive
interoperability}\label{library-description-targeting-reactive-interoperability}}

In Fig. fig\_archit a generic architecture of the Machine to Machine
(M2M) interoperability is presented. A detailed description of this
model is covered by \cite{RefWorks:doc:5d6cdbbbe4b082ad50f3a83e}, but in
this section, the most important features of this model have been
abstracted to settle a foundation for further discussion related to
systematic design, development, and deployment of the mobile
applications compliant with the more general IoT concept. The main aim
is the examination of how the model addresses challenges defined in
Section \ref*{sec.intro}.

\hypertarget{mobility}{%
\subsection{Mobility}\label{mobility}}

For any generic solution addressing the development and deployment of
the cyber-physical system the data holder mobility behavior must be
considered apart from the described above features. Mobile data means
that it may come from mobile devices or be generated in unpredictable
attachment points.

If the data origin holding asset is a mobile device it means that we
must deal with the dynamic Internet attachment point. A typical example
of this scenario is portable monitoring or control of the underlying
process, for example, a portable healthcare solution. Another scenario
is ad hoc interconnected data holder assets, for example, cars entering
a service area.

In case the generation places of data are arbitrary it means that the
data appearance must be recognized and processed as an event. A good
example of this scenario is a product (e.g.\textasciitilde hygiene
products, cosmetics, drugs, cars, cigarettes) global tracking system -
an application domain where the Internet of Things (IoT) term has been
coined
\cite{RefWorks:doc:5d87d1c9e4b0bc72a68d7b46, RefWorks:doc:5d87d02be4b0e88bdacab9a7}.
In this context, the IoT is all about:

\begin{itemize}
\tightlist
\item
  \textbf{mobile data fetching} - how to gather data from mobile things
  (data holder assets)
\item
  \textbf{mobile data distribution} - how to transfer the data over the
  Internet to all places where it could be processed
\item
  \textbf{mobile data processing} - how to integrate consistently the
  partial data into a selected application as one whole to improve
  selected process performance
\end{itemize}

One of the arguments for the Internet of Things is allowing distributed
yet interlinked devices, machines, and objects (data holders) to
interact with each other without relying on human interaction to set-up
and commission the embedded intelligence.

In case any kind of mobility has to be considered the next engineering
challenge is dynamic discoverability on the network and the possibility
of establishing semantic and security context of the parts composing the
cyber-physical distributed application.

\begin{itemize}
\tightlist
\item
  Machine To Machine communication based on the semantic-data
\item
  OOI PubSub Implementation Architecture
\item
  Simple, complex and structural data processing
\end{itemize}

Any information about available reusable deliverables related to this
work.

\hypertarget{iot}{%
\subsection{IoT}\label{iot}}

Internet of Things is all about

\begin{itemize}
\tightlist
\item
  Mobile data fetching -- how to gather the data from mobile devices
  (things)
\item
  Mobile data subscription -- how to transfer the data over the Internet
  to a place where it could be subscribed.
\item
  Mobile data consumption -- data processing, computation
\end{itemize}

To deploy this scenario

\begin{itemize}
\tightlist
\item
  the mobile data must be sent over the Internet using messages;
\item
  the payload of these messages is consumed by a ultimate destination
  responsible to process it according to the solution scenario,
  e.g.~displacing recovered data using web UI
\item
  the application as an OPC UA client consumes the exposed data and
  generates revenue for the end-user.
\end{itemize}

The phrase ``Internet of Things'' started its life as the title of a
presentation made in 1999 and aimed at explaining a new idea of radio
frequency identification (RFID) in the context of the supply chain
performance. It is clear that it doesn't mean that someone has any right
to control how others use the phrase, but my point is that a precise
term definition is important for working together on: common rules,
architecture, solutions, requirements, capabilities, limitations, etc.
In practice having a common definition it is possible to check a
selected technology, solution or product capabilities against
requirements of the application entitled to use this term.

My proposal of the Internet of Things definition is as follows:

\hypertarget{from-ooi-ri-mpostolmanuscript.tex}{%
\subsection{from
OOI-RI-MPostolManuscript.tex}\label{from-ooi-ri-mpostolmanuscript.tex}}

\hypertarget{reactive-interoperability-implementation}{%
\subsubsection{Reactive Interoperability
Implementation}\label{reactive-interoperability-implementation}}

This section covers an analysis of how to use the proposed domain model
\texttt{\textbackslash{}cite\{mpostol2020\}} to make strategic design
decisions and distribute functionality to reusable loosely coupled parts
using the dependency injection software engineering and adaptive
programming using the approach proposed in
\texttt{\textbackslash{}cite\{RefWorks:doc:5d9796cbe4b0f66c52dccf04\}}.

The \textbf{Reactive Interoperability} concept has been implemented as
an open-source library named \texttt{SemanticData} in the project
Object-Oriented Internet \cite{RefWorks:doc:5c66740ae4b081adf5804596}
designed to be a foundation for developing application programs that are
taking part in the message-centric communication pattern. From the above
discussion, we can learn that the main design decisions must concern
standardization and flexibility. Standardization needs the selection of
an international interoperability specification to make the library
ready to be adopted by the multi-vendor environment. Flexibility
requires an architecture that promotes the polymorphic independent
implementation of essential functions.

Piece by piece integration of a cyber-physical system using multi-vendor
products requires that M2M communication employs international standards
as the interoperability foundation. Following the presented conclusions,
OPC Unified Architecture Part 14 PubSub
\cite{RefWorks:doc:5d98837de4b055984c0eecf0} is selected in this
respect. By design, this standard supports the required
publisher-subscriber communication pattern. It must be stressed that by
design it provides only an abstract specification. Abstract means that
the standard must not limit the implementation strategy. This
relationship shall be recognized as the proof of concept to verify that
the implementation of the proposed model is feasible to be compliant
with the selected standard as envisioned and open to support all
functionality required to establish the interoperability context.

For many parts of the \textbf{Reactive Application} domain model (Sect.
\ref*{sec.DomainModel}) a polymorphic approach to implementation is
required. To promote the polymorphic ready solution the following
concepts have been adopted:

\begin{itemize}
\tightlist
\item
  \texttt{separation\ of\ concerns} - to allow an independent
  development of the parts \cite{RefWorks:doc:5d92609be4b02eb43d372bd1},
\item
  \texttt{dependency\ injection} - to allow late binding of separately
  implemented parts \cite{RefWorks:doc:5d925b77e4b030b4e0596f5d}.
\end{itemize}

In Fig. the implementation architecture of the \textbf{Reactive
Application} is proposed. The common functionality has been implemented
as the Software Development Kit (SDK) available as the NuGet package
\texttt{\textbackslash{}cite\{RefWorks:doc:5c66740ae4b081adf5804596\}}.
To promote the polymorphic approach, it has the factory class
\texttt{DataManagementSetup} that is a placeholder to gather all
injection points used to compose external parts. To be injected the
parts must be compliant with appropriate contracts expressed as the
following interfaces representing the following functionality:

\begin{itemize}
\tightlist
\item
  \texttt{IBindingFactory} - bidirectional data exchange with the
  underlying process,
\item
  \texttt{IConfigurationDataFactory} - the configuration data access,
\item
  \texttt{IMessageHandlerFactory} - pushing the \textbf{Message}
  entities to/pulling from \emph{Distribution Channel} (Fig.
  \ref*{fig_DomainModel}),
\item
  \texttt{IEncodingFactory} - searching a dictionary containing value
  converters.
\end{itemize}

It is expected that the functionality implementation represented by
these interfaces is provided as external composable parts.

\hypertarget{process-data-access}{%
\paragraph{Process Data Access}\label{process-data-access}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{label\{process-data-access\}}
\end{Highlighting}
\end{Shaded}

The \emph{DataRepository} represents data holding assets in the
\emph{Reactive Application} and, following the proposed architecture,
the \emph{IBindingFactory} interface is implemented by this external
part. It captures functionality responsible for accessing the process
data from \emph{LocalResources}. The \emph{LocalResources} represents an
external part that has a very broad usage purpose. For example, it may
be any kind of the process data source/destination, i.e.~\emph{Raw Data}
or \emph{Address Space Management} (Fig. \ref*{fig_archit}). By design,
the \emph{DataRepository} and associated entities,
i.e.~\emph{Local Resources}, \emph{Consumer}, \emph{Producer} have been
implemented as external parts, and consequently, the application scope
may cover practically any concern that can be separated from the core
\emph{Reactive Application} implementation.

Depending on the expected network role the library supports the external
implementation of:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{\textbackslash{}begin}\NormalTok{\{}\ExtensionTok{itemize}\NormalTok{\}}
  \FunctionTok{\textbackslash{}item} \FunctionTok{\textbackslash{}emph}\NormalTok{\{Consumer\} - entities processing data from incoming messages,}
  \FunctionTok{\textbackslash{}item} \FunctionTok{\textbackslash{}emph}\NormalTok{\{Producer\} - entities gathering process data and populating outgoing messages.}
\KeywordTok{\textbackslash{}end}\NormalTok{\{}\ExtensionTok{itemize}\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The \texttt{Consumer} and \texttt{Producer} parts are derived from the
\texttt{DataRepository} Fig. The \texttt{Consumer} uses the
\texttt{IBindingFactory} to gather the data recovered from the
\textbf{Message} instances pulled from the \textbf{Distribution
Channel}. The received data may be processed or driven to any data
destination. The \texttt{Producer} mirrors the \texttt{Consumer}
functionality and, after reading data from an associated source,
populates the \texttt{Message} using the gathered data.

\hypertarget{cloud-to-sensors-field-level-connectivity}{%
\section{Cloud to Sensors Field Level
Connectivity}\label{cloud-to-sensors-field-level-connectivity}}

\hypertarget{architecture}{%
\subsection{Architecture}\label{architecture}}

\hypertarget{introduction-1}{%
\subsubsection{Introduction}\label{introduction-1}}

As it was explained in Sect 1, to follow the Industry 4.0 concept a
hybrid environment integrating reactive Machine to Machine
interconnection and interactive web-based user interface is required.
The main challenge of the solution in concern is to design a generic but
reusable architecture that addresses interoperability of these diverse
interconnection scenarios ruled by different requirements, namely

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{machine-centric} machine to machine real-time mobile
  interoperability
\item
  \textbf{human-centric} cloud-based front-end
\end{enumerate}

Interconnection of the reactive \textbf{machine-centric} and interactive
\textbf{human-centric} environments can be implemented by applying one
of the following scenarios:

\begin{itemize}
\tightlist
\item
  \textbf{direct interconnection} - cloud-based dedicated communication
  services are engaged to attach it to the cyber-physical system making
  up a consistent M2M communication network using a common protocol
  stack
\item
  \textbf{gateway based interconnection} - native build-in communication
  services allows attaching the cloud to the cyber-physical system using
  an out-of-bound protocol stack
\end{itemize}

In the solution in concern, the interconnection of assets is not enough
hence their interoperability is expected. In this case, using the same
communication stack must be recognized as only a necessary condition. To
support interoperability common data understanding is required. By
design, the direct approach requires that the cloud has to be compliant
with the interoperability standard the cyber-physical system uses. As a
result, it becomes a consistent part of the cyber-physical system.
Additionally, to meet this requirement the cloud and cyber-physical
systems have to establish

\begin{itemize}
\tightlist
\item
  directly the same semantic-context
\item
  directly the same security-context
\end{itemize}

The possibility to establish a common semantic-context in the
multi-vendor environment makes communication standardization especially
important. In this case, it is required that the encoding of the payload
of messages exchanged over the network (Data Transfer Object - TDO) is
standardized so that the payload can be factored on the data-gathering
site and consumed on the ultimate destination data processing sites.
Security between the data origin and ultimate data destination refers to
the protection of messages (security-context) against malicious users.
It is required that communicating parties are using the same
cyber-security measures.

\hypertarget{why-not-direct}{%
\subsubsection{why not direct}\label{why-not-direct}}

The decision to follow the \textbf{direct interconnection} scenario must
be derived from an analysis of the capabilities of available services in
concern. However, for the development strategy of this type of solutions
this analysis can be done partially taking into account two features
that can be considered invariable:

\begin{itemize}
\tightlist
\item
  by design the cloud-based services must be virtual - they are used to
  handle many solutions at the same time
\item
  by design the M2M communication is usually constrained by the
  real-time requirements
\end{itemize}

In practice, the set of assets embedded in the cyber-physical system is
very stable. On the another hand, the virtualization of services means
that they must be very flexible to handle the attachment of new assets
proactively (acting in advance) at run time. As a result, by design, the
cloud services must be repressible to register and authenticate devices
exposing endpoints in the public network to allows the device to access
a provisioning cloud service. It requires that a session over the
Internet has to be established by the data holding asset at a
preparation step.

To meet the requirements of real-time distributed control the
cyber-physical system may use protocols applicable only to local
computer networks (e.g.~multicast IP, Ethernet, TSN, etc.). Because the
cloud services support only protocols handling interconnection over the
Internet the interaction with the cloud requires remote agents,
i.e.~agents attached locally to the M2M network implemented applying one
of the following archetypes:

\begin{itemize}
\tightlist
\item
  \textbf{edge device} - remote cloud agent acting as an intermediary
  for nodes of the cyber-physical network
\item
  \textbf{field level gateway} - a dedicated custom device acting as an
  intermediary for nodes of the cyber-physical network
\item
  \textbf{embedded gateway} - a software part composed into a selected
  node of the cyber-physical network
\end{itemize}

\textbf{Edge device} is a device that connects directly to the cloud
services but acts as an intermediary for other devices called leaf
devices. Additionally, it allows the selection of initial data
processing and execution of them using local resources. The \textbf{edge
device} may be located close to the leaf devices and attached to the
cyber-physical network using protocols applicable only to local computer
networks. In this scenario, it is possible to use a custom protocol
stack to get connected to the \textbf{edge device} with the cloud and
helps to save the bandwidth thanks to sending only the results of local
processing. In this approach, the \textbf{edge device} is part of cloud
vendor products and cannot be recognized as a generic solution that can
be used to connect to other clouds at the same time.

The \textbf{field level gateway} is also build atop of the middleware
concept. The only difference compared with the \textbf{edge device} is
necessity to use officially supported by the cloud vendor services to
get connected. In this scenario the process data may be transferred to
many clouds at the same time provided that the gateway offers this
functionality.

\begin{figure}
\centering
\includegraphics{../.Media/StrategyDomainModel.png}
\caption{Strategy Domain Model}
\end{figure}

Unlike the above described solutions, the \textbf{embedded gateway} is
not derived from the middleware concept. The domain model for this
archetype is presented in the Fig. Promoting separation of concern
design principle, the gateway functionality should be implemented as a
self-contained software part embedded in the \texttt{Networking} service
of the \texttt{Cipher-physical\ node}. Main functionality of this
component is to transfer selected data between
\texttt{Cyber-physical\ network} using \texttt{Networking} services of
an existing \texttt{Cyber-physical\ node} and
\texttt{Cloud-based\ front-end} using officially supported by the cloud
vendor interconnection services.

The \textbf{embedded gateway} archetype relaxes most of the issues
described above: cipher-physical network real-time behavior, data
encoding incompatibility, security-context differences to name only a
few. The main goal of this article is to provide proof that the
\textbf{embedded gateway} archetype implementation is possible based on
a generic architecture that can be used as a foundation for the
integration of the heterogenous environments in concern. The proposed
implementation is designed for selected interoperability standard and
cloud product.

\hypertarget{why-pubsub}{%
\subsection{Why pubsub}\label{why-pubsub}}

To comply with the Industry 4.0 communication criterion, even the lowest
category requires that the product must be addressable over the network
via TCP/UDP or IP and has to support the OPC UA Information Model. As a
result, any product being advertised as Industry 4.0 enabled must be OPC
UA-capable somehow. To support the multi-vendor environment OPC Unified
Architecture interoperability standard has been selected. OPC UA
supports the following two patterns to be used to transfer data between
communicating parties:

\begin{itemize}
\tightlist
\item
  connection-oriented: requires a session that has to be established
  before any data can be sent between sender and receiver
\item
  connectionless-oriented: the sender may start sending messages (called
  packets or datagrams) to the destination without any preceding
  handshake procedure
\end{itemize}

Using the connection-oriented communication pattern it is difficult or
even impossible to gather and process mobile data (Sec. I), which is one
of the Internet of Things paradigms. OPC UA Part 14 PubSub offers the
connectionless approach as an additional option to session based
client-server interoperability and is a consistent part of the OPC UA
specifications suit. As the result it can be recognized as the IoT ready
technology.

\begin{quote}
{[}29{]} Mariusz Postol, UA Part 14: PubSub Main Technology Features in
Object Oriented Internet, https://github.com/mpostol/OPC-UA-OOI, 2019,
DOI: 10.5281/zenodo.1198852
\end{quote}

\hypertarget{why-azure}{%
\subsection{Why Azure}\label{why-azure}}

The presented proposals in the article are backed by proof of concept
reference implementations. For this study, prototyping addresses
Microsoft Azure cloud products. There are many reasons for selecting
Azure to accomplish cloud-based front-end of CFS. Azure offers
Infrastructure as a Service (IaaS) and Platform as a Service (PaaS)
capabilities. As a result, the platform can be used not only as a
cloud-based front-end for CFS. By design, the Azure services are
compliant with Security Development Lifecycle (SDL) an industry-leading
security process. It is also compliant with the new international
standard for cloud privacy, namely ISO 27018. Solutions hosted on Azure
are scaled up to millions of users without any additional coding. For
the development of the CFS front-end, it is essential that Azure
provides very efficient storage services usefully for real-time process
data archival. Azure provides a vast variety of hybrid connections
including but not limited to virtual private networks (VPNs), caches,
content delivery networks (CDNs), ExpressRoute, and IoT dedicated
services that can be directly used to implement cloud-based front-end
for CFS. Because it is also integrated with other Microsoft tools like
Office 365, Outlook, and SharePoint using Azure allows preserving
investment and exporting process data to the mentioned tools. Azure also
offers services supporting analytics and intelligence capabilities for
further improving business processes and decision making. It is the only
cloud platform that offers Blockchain as a Service (BaaS), Machine
Learning, Bots, and Cognitive APIs capabilities.

Azure aids Internet protocols and open standards such as JSON, XML,
SOAP, REST, MQTT, AMQP, and HTTP. A software development kits for C\#,
Java, PHP, and Ruby are available for custom applications. Azure
provides services supporting data exchange over the OPC UA, but they
don't support pubsub compliant with the OPC UA Part-14. Connectivity
services on the network use JSON-based Data Transfer Object encoded
based on schema derived from the solution metadata.

More detailed description of the selected Azure features in context of
the application in concern are covered by the Sec.
\texttt{azure-main-technology-features}.

\hypertarget{why-ooi}{%
\subsection{Why OOI}\label{why-ooi}}

Based on the sessionless and session-oriented communication patterns
examination against the IoT requirements (cite mpostol 2020) it could be
concluded that the connectionless pattern better suites issues related
to the assets mobility and traffic asymmetry that is characteristic for
the application domains in concern. Additionally, to promote
interoperability and address the demands of the M2M communication in the
context of a multi-vendor environment the prototyping should use an
framework that must be compliant with the OPC UA Part 14 PubSub spec.
According to proposed architecture presented in Fig. above to implement
the \texttt{Embedded\ Gateway} as a composable part of the
\texttt{Cipher-physical\ Node} a library implementing
\texttt{Networking} functionality in compliance with mentioned above
specification is a starting point for further development. Additionally
it must be assumed that the library used to deploy
\texttt{Embedded\ Gateway} support dependency injection and be capable
to compose an external part supporting Azure/pubsub gateway
functionality. The composition process must be available without
modification of the core code of an existing library. As a result the
prototyping is to be limited to implementation of the
\texttt{Embedded\ Gateway} software part only.

A library that meets all these requirements has been implemented
consistently with the Object-Oriented Internet paradigm
\texttt{\textbackslash{}footnote\{\textbackslash{}url\{https://github.com/mpostol/OPC-UA-OOI\}\}}
\texttt{\textbackslash{}cite\{RefWorks:doc:5c66740ae4b081adf5804596\}}
worked out in an open-source project. The
\texttt{cite\ \{mpostol\ 2020\}} covers the description of a reference
application program implementation proving that it is possible to design
universal architecture targeting reactive interoperability as a
consistent part of the Object-Oriented Internet concept compliant with
the OPC UA PubSub
\texttt{\textbackslash{}cite\{RefWorks:doc:5d98837de4b055984c0eecf0\}}
international standard. According to the presented implementation and
evaluation, using the dependency injection and late binding, the
application program can be seamlessly adapted to the production
environment and scales well. This approach also improves flexibility and
adaptability of the existing solutions against any modification of the
production environment including but not limited to the selected
interoperability standard change.

Sect. \texttt{OPC\ UA\ PubSub\ Main\ Technology\ Features} provides more
detailed description of this library and new functionality
(\texttt{Embedded\ Gateway} part deployment process.

The following subsections covers description of the current state of
technologies with regards to OPC UA pubsub and Azure cloud-based IoT
enabler.

\hypertarget{review-of-technologies}{%
\subsection{Review of Technologies}\label{review-of-technologies}}

add here subsections related to the Azure and OOI

\hypertarget{azure-gateway-datarepository-implementation}{%
\section{Azure Gateway DataRepository
Implementation}\label{azure-gateway-datarepository-implementation}}

\hypertarget{preface}{%
\subsection{Preface}\label{preface}}

This section describes an example implementation of an OPC UA PubSub to
Azure gateway. This gateway is implemented as a composable part of the
Reactive Networking Application (\texttt{RxNetworking\ App}). The
\texttt{RxNetworking\ App} is an aggregation of \texttt{Producer} and
\texttt{Consumer} entities derived from \texttt{DataRepository}. They
must provide interconnection to real-time process data, hence they are
recognized as an extension of the \texttt{DataRepository} class.
\texttt{AzureGateway} part fulfills the \texttt{Consumer} role and uses
out-of-band communication to push process data to the cloud.

\hypertarget{architecture-1}{%
\subsection{Architecture}\label{architecture-1}}

Domain model presenting relationship between the: Azure, PubSub Gateway,
Device, Design and development tools

The \texttt{AzureGateway} functional package has been implemented based
on the \texttt{Consumer} concept. This particular \texttt{Consumer}
implements \texttt{IBindingFactory} interface to gather the data
recovered from the \texttt{Message} instances pulled from the
\texttt{Distribution\ Channel}. The received data is driven to the Azure
services using configured out-of-band' protocol. An instance of the
\texttt{IBindingFactory} is responsible to create objects implementing
\texttt{IBinding} that can be used by the \texttt{Consumer} to forward
the data retrieved from \texttt{NetworkMessag} received over the wire to
Azure services.

The proposed implementation of the Azure gateway proves that the
\texttt{DataRepository} and associated entities,
i.e.~\texttt{Local\ Resources}, \texttt{Consumer}, \texttt{Producer} can
be implemented as external parts, and consequently, the application
scope may cover practically any concern that can be separated from the
core PubSub communication engine implementation.

The article provides an introductory understanding of the steps required
to implement the \texttt{Consumer} role of
\texttt{OOI\ Reactive\ Application}. The \texttt{ReferenceApplication}
is an example application of \texttt{Semantic-Data} reactive networking
based on {[}OPC UA PubSub{]}{[}OPC.UA.PubSub{]} specification. The
document {[}OPC UA PubSub Main Technology Features{]}{[}PubSubMTF{]}
covers a description of selected fetuses relevant to this specification.

It is proof of the concept that out-of-band communication for OPC UA
PubSub can be implemented based on the \texttt{DataRepository} concept.

Here are steps undertook to implement the \texttt{Consumer} role in the
application:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{DataManagementSetup}: this class has been overridden by the
  \texttt{PartDataManagementSetup} class and it initializes the
  communication and binds data fields recovered form messages to local
  resources.
\item
  \texttt{IEncodingFactory} and \texttt{IMessageHandlerFactory}: have
  been implemented in independent libraries and \texttt{Consumer}
  doesn't depend on this implementation - current implementation of the
  interfaces is localized as services using an instance of the
  \texttt{IServiceLocator} interface.
\item
  \texttt{IBindingFactory}: has been implemented in the class
  \texttt{PartBindingFactory} that is responsible to gather the data
  recovered from the \texttt{Message} instances pulled from the
  \texttt{Distribution\ Channel}. The received data is driven to the
  Azure services using configured out-of-band protocol.
\item
  \texttt{IConfigurationFactory}: the class
  \texttt{PartConfigurationFactory} implements this interface to be used
  for the configuration file opening.
\end{enumerate}

\hypertarget{datamanagementsetup-implementation}{%
\subsubsection{\texorpdfstring{\texttt{DataManagementSetup}
implementation}{DataManagementSetup implementation}}\label{datamanagementsetup-implementation}}

The \texttt{PartDataManagementSetup} constructor initializes all
properties, which are injection points of all parts composing this role.

In this example, it is assumed that
\href{https://www.nuget.org/packages/CommonServiceLocator}{\texttt{ServiceLocator}}
is implemented to resolve references to any external services.

Finally the \texttt{DataManagementSetup.Start()} method is called to
initialize the infrastructure, enable all associations and start pumping
the data.

\hypertarget{ibindingfactory-implementation}{%
\subsubsection{\texorpdfstring{\texttt{IBindingFactory}
implementation}{IBindingFactory implementation}}\label{ibindingfactory-implementation}}

Implementation of this interface is a basic step to implement
\texttt{Consumer} functionality. The \texttt{DataRepository} represents
data holding assets in the \texttt{RxNetworking\ App} and, following the
proposed architecture, the \texttt{IBindingFactory} interface is
implemented by this external part. It captures functionality responsible
for accessing the process data represented by the
\texttt{LocalResources}. The \texttt{LocalResources} represents the
external part that has a very broad usage purpose. For example, it may
be any kind of process data source/destination, and to name a few
\texttt{Raw\ Data}, \texttt{OPC\ UA\ Address\ Space\ Management}, and
\texttt{Azure} services in this case.

\hypertarget{configuration}{%
\subsection{Configuration}\label{configuration}}

\hypertarget{iconfigurationfactory-implementation}{%
\subsubsection{\texorpdfstring{\texttt{IConfigurationFactory}
implementation}{IConfigurationFactory implementation}}\label{iconfigurationfactory-implementation}}

Implementation of this interface is straightforward and based entirely
on the library UAOOI.Configuration.Networking available as the NuGet
package. In a typical scenario, this implementation should not be
considered for further modification. The only open question is how to
provide the name of the file containing the configuration of this role.

\hypertarget{protocol-selection}{%
\subsection{Protocol selection}\label{protocol-selection}}

From the description covered by the Sec. and the Sec. the Azure supports
the HTTP, AMQP, MQTT, but the PubSub Ethernet, UDP, AMQP, MQTT. If the
Ethernet or UDP has been selected to build interconnection based on
PubSub direc interoperability with the PubSub is impossible because the
Azure doesn't offer these protocol as native communication services.

\hypertarget{data-mapping}{%
\subsection{data mapping}\label{data-mapping}}

For both the schema is different Data Transfer Object encoding

The Azure uses JSON based Data Transfer Object encoding and schema
defined based on the solution metadata. The pubsub uses json and binary
Data Transfer Object encoding. If JSON is used possibility to establish
semantic context depends on the Azure metadata definition. In case
PubSub uses binary encoding establishing interconnection is impossible.

\hypertarget{security}{%
\subsection{Security}\label{security}}

Azure and PubSub uses different security mechanism so establishing
directly security context is impossible at all

\hypertarget{deployment-phases}{%
\subsection{Deployment phases}\label{deployment-phases}}

\begin{itemize}
\tightlist
\item
  Design
\item
  Gateway and devices registration
\item
  Authentication
\item
  Device/Service association
\item
  Device/Application association
\item
  Establishing session

  \begin{itemize}
  \tightlist
  \item
    Device/Device Template (Device Capability Model) association -
    establishing a semantic-context
  \item
    Security management - establishing security-context
  \end{itemize}
\item
  Interconnection - exchange of data
\item
  Maintenance
\end{itemize}

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

The OPC UA PubSub to Azure gateway (\texttt{AzureGateway})
implementation has been just published on GitHub as the open-source (MIT
licensed) as a part of the more general concept of the Object-Oriented
Internet reactive networking. It is proof of the concept that

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  OPC UA PubSub can be implemented as a powerful standalone package - no
  C/S dependency
\item
  Azure interoperability can be implemented as an out-of-band
  communication (MQTT, AMQP, HTTP) - no PubSub dependency
\item
  Process data functionality can be composable at run-time - no
  programming required
\end{enumerate}

\hypertarget{from-ooi-ri-mpostolmanuscript.tex-1}{%
\subsection{From
OOI-RI-MPostolManuscript.tex}\label{from-ooi-ri-mpostolmanuscript.tex-1}}

The described solution proves that it is possible tio implement Azure
couple as \ldots{}

The \emph{DataRepository} represents data holding assets in the
\emph{Reactive Application} and, following the proposed architecture,
the \emph{IBindingFactory} interface is implemented by this external
part. It captures functionality responsible for accessing the process
data from \emph{LocalResources}. The \emph{LocalResources} represents an
external part that has a very broad usage purpose. For example, it may
be any kind of the process data source/destination,
i.e.\textasciitilde{}\emph{Raw Data} or \emph{Address Space Management}
(Fig. \ref*{fig_archit}). By design, the \emph{DataRepository} and
associated entities, i.e.\textasciitilde{}\emph{Local Resources},
\emph{Consumer}, \emph{Producer} have been implemented as external
parts, and consequently, the application scope may cover practically any
concern that can be separated from the core \emph{Reactive Application}
implementation.

\end{document}
