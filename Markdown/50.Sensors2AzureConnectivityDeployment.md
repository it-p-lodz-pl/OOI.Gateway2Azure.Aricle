# Cloud to Sensors Field Level Connectivity

## Architecture

### Introduction

As it was explained in Sect 1, to fallow the Industry 4.0 concept a hybrid environment integrating reactive Machine to Machine interconnection and interactive web-based user interface is required. The main challenge of the solution in concern is to design a generic but reusable architecture that addresses interoperability of these diverse interconnection scenarios ruled by different requirements, namely

1. **machine-centric** machine to machine real-time mobile interoperability
1. **human-centric** cloud-based front-end

Interconnection of the reactive **machine-centric** and interactive **human-centric** environments can be implemented by applying one of the following scenarios:

- **direct interconnection** - cloud-based dedicated communication services are engaged to attach it to the cyber-physical system making up a consistent M2M communication network using a common protocol stack
- **gateway based interconnection** - native build-in communication services allows attaching the cloud to the cyber-physical system using an out-of-bound protocol stack

In the solution in concern, the interconnection of assets is not enough hence their interoperability is expected. In this case, using the same communication stack must be recognized as only a necessary condition. To support interoperability common data understanding is required. By design, the direct approach requires that the cloud has to be compliant with the interoperability standard the cyber-physical system uses. As a result, it becomes a consistent part of the cyber-physical system. Additionally, to meet this requirement the cloud and cyber-physical systems have to

- directly establish the same semantic-context
- directly establish the same security-context

The possibility to establish a common semantic-context in the multi-vendor environment makes communication standardization especially important. In this case, it is required that the encoding of the payload of messages exchanged over the network (a Data Transfer Object - TDO) is standardized so that the payload can be factored on the data-gathering site and consumed on the ultimate destination data processing sites. Security between the data origin and ultimate data destination refers to the protection of messages (security-context) against malicious users. It is required that communicating parties are using the same cyber-security measures.

### why not direct

The decision to follow the **direct interconnection** scenario must be derived from an analysis of the capabilities of available services in concern. However, for the development strategy of this type of solutions this analysis can be done partially taking into account two features that can be considered invariable:

- by design the cloud-based services must be virtual - they are used to handle many solutions at the same time
- by design the M2M communication is usually constrained by the real-time requirements

In practice, the set of assets embedded in the cyber-physical system is very stable. On the other hand, the virtualization of services means that they must be very flexible to handle the attachment of new assets proactively (acting in advance) at run time. As a result, by design, the cloud services must be repressible to register and authenticate devices exposing endpoints in the public network to allows the device to access a provisioning cloud service. It requires that a session over the Internet has to be established by the data holding asset at a preparation step.

To meet the requirements of real-time distributed control the cyber-physical system may use protocols applicable only to local computer networks (e.g. multicast IP, Ethernet, TSN). Because the cloud services support only protocols handling interconnection over the Internet the interaction with the cloud requires remote agents, i.e. agents attached locally to the M2M network. In any case, it must be recognized as middleware and implemented as:

- **edge device** - remote cloud agent acting as an intermediary for nodes of the cyber-physical network
- **field level gateway** - a dedicated custom device acting as an intermediary for nodes of the cyber-physical network
- **embedded gateway** - a software part composed into a selected node of the cyber-physical network

**Edge device** is a device that connects directly to the cloud services but acts as an intermediary for other devices called leaf devices. Additionally, it allows the selection of initial data processing and execution of them using local resources. The edge device may be located close to the leaf devices and attached to the cyber-physical network using protocols applicable only to local computer networks. In this scenario, it is possible to use a custom protocol stack to get connected to the **Edge device** with the cloud and helps to save the bandwidth thanks to sending only the results of local processing. In this approach, the **Edge device** is part of cloud vendor products and cannot be recognized as a generic solution that can be used to connect to other clouds at the same time.

The **field level gateway** is also build on the middleware concept. The only difference compared with the **Edge device** is necessity to use officially supported by the cloud vendor services to get connected. In this scenario the process data may be transferred to many clouds at the same time provided that the gateway offers this functionality.

Unlike the previous solutions, the **embedded gateway** is not derived from the middleware concept. The domain model is presented in the Fig. Promoting separation of concern software development engineering approach, the gateway functionality should be implemented as a self-contained software part embedded in the `Networking` service of the `Cipher-physical node`. Main functionality of this component is to transfer selected data between `Cipher-physical network` using `Networking` services of an existing `Cipher-physical node` and `Cloud-based Front-end` using officially supported by the cloud vendor interconnection services.

The **embedded gateway** archetype relaxes most of the issues described above. To name only a few; cipher-physical network real-time behavior, data encoding incompatibility, security-context differences. The main goal of this article is to provide proof that that the **embedded gateway** archetype implementation is possible based on a generic architecture that can be used as a foundation for the integration of the heterogenous environments in concernThe proposed implementation is designed for interoperability standard and selected cloud products.


- selected interoperability standard supporting reactive nodes relationship on the foundation of an existing standalone networking library, and
- selected cloud products

- as a standalone software part composable into the networking library using dependency injection that guaranties the most popsicle level of separation


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  reactive interoperability M2M communication based on the OPC UA
  standard can be implemented as a powerful standalone library without
  dependency on the Client/Server session-oriented archetype
\item
  Azure interoperability can be implemented as an external part
  employing out-of-band communication without dependency on the OPC UA
  implementation
\item
  the proposed generic architecture allows that the gateway
  functionality is composable at run-time - no programming required
\end{enumerate}

It is rather a plug-in providing additional functionality on the foundation of an existing cyber

a supervisory control system to isolated islands of automation and all of them deal with the same real-time process
A very important feature of the real-time systems is their intrinsic reliability
a consistent sole representation of a distributed real-time process
Cache is an intermediate storage of real-time process data.


The Azure uses JSON based Data Transfer Object encoding and schema defined based on the solution metadata. The pubsub uses json and binary Data Transfer Object encoding. If JSON is used posibility to establish semantic-context depends on the Azure metadata definition. In case PubSub uses binary encoding stablishin inteconnection is imposible.

Azure and Pub uses different security mechanizms so establishing directtly security context is imposible at all

. For both the schema is different Data Transfer Object encoding

Described above differences of both solutions make this approach impractical or evan imposable to be applied in typical cases.

field level gateway

### why gateway


 Middleware may be attached to the local network in case the Ethernet ot multicast IP are in use.

How does multicast IP work?

Using multicast, a source can send a single copy of data to a single multicast address, which is then distributed to an entire group of recipients. ... A source host sends data to a multicast group by simply setting the destination IP address of the datagram to be the multicast group address.

### why pubsub

### Why Azure

because Microsoft supports development of the OPC UA, so some product are OPC UA aware, but no one implement PubSub as the **embedded gateway**

We have selected [IoT Central](https://docs.microsoft.com/azure/iot-central/core/) because:

- provides process data visualization user interface
- allows to describe devices using metadata containing telemetry data types

- **Connectivity** - Describe reactive nature of the Azure monitoring process data (telemetry) services.

### Why OOI

